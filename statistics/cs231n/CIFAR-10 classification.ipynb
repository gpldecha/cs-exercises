{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10\n",
    "\n",
    "Learning a classifier for the [CIFAR-10](http://www.cs.utoronto.ca/~kriz/cifar.html) dataset.\n",
    "\n",
    "* [reference 1](https://appliedmachinelearning.blog/2018/03/24/achieving-90-accuracy-in-object-recognition-task-on-cifar-10-dataset-with-keras-convolutional-neural-networks/)\n",
    "\n",
    "* [reference 2](https://keras.io/examples/cifar10_cnn/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Python version is 3.6.8\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "sys.path.append('/home/guillaume/cpp_work_space/cs-exercises/python/')\n",
    "import machine_learning_utils.utils as ml_utils\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"The Python version is %s.%s.%s\" % sys.version_info[:3])\n",
    "import machine_learning_models.cifar_10_models as models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "tf.compat.v1.keras.backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(name='data_batch_1', folder='/home/guillaume/Data/cifar-10-python'):\n",
    "    batch = ml_utils.load_data(os.path.join(folder, name))\n",
    "    data = batch[b'data']\n",
    "    labels = np.array(batch[b'labels'])\n",
    "    R = data[:, :1024].reshape((-1, 32, 32))\n",
    "    G = data[:, 1024:(2*1024)].reshape((-1, 32, 32))\n",
    "    B = data[:, (2*1024):].reshape((-1, 32, 32))\n",
    "    return np.stack((R, G, B), axis=3), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1\n",
      "Loading 2\n",
      "Loading 3\n",
      "Loading 4\n",
      "Loading 5\n"
     ]
    }
   ],
   "source": [
    "num_batches = 5\n",
    "images_set = list()\n",
    "labels_set = list()\n",
    "for i in range(num_batches):\n",
    "    print('Loading {}'.format(i+1))\n",
    "    images, labels = get_dataset('data_batch_' + str(i+1))\n",
    "    images_set.append(images)\n",
    "    labels_set.append(labels)\n",
    "images = np.concatenate(images_set)\n",
    "labels = np.concatenate(labels_set)\n",
    "\n",
    "test_images, test_labels = get_dataset('test_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614.4 MB\n"
     ]
    }
   ],
   "source": [
    "images = images.astype(np.float32)\n",
    "images /= 255\n",
    "print('{} MB'.format(images.nbytes/1e6))\n",
    "test_images = test_images.astype(np.float32)\n",
    "test_images /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percentage = 0.2\n",
    "train_data, train_label, test_data, test_label = ml_utils.split_test_train(test_percentage, images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(images[2, :, :, :])\n",
    "plt.show()\n",
    "print(images[2, :, :, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_label))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_label))\n",
    "\n",
    "batch_size = 128\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1000).batch(batch_size).repeat()\n",
    "test_dataset  = test_dataset.shuffle(buffer_size=1000).batch(batch_size).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=90,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True, \n",
    "    validation_split=0.2)\n",
    "image_data_generator.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 30, 30, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 15, 15, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 13, 13, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 1,250,858\n",
      "Trainable params: 1,250,858\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = models.create_conv_net()\n",
    "model = models.create_keras_example_1()\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=6, monitor='val_loss', restore_best_weights=True),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='/home/guillaume/cpp_work_space/cs-exercises/statistics/tensorflow/checkpoints/cifar_10/', \n",
    "                                     monitor='val_loss', \n",
    "                                     save_weights_only=True),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs/model2/')\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0805 21:08:51.129033 140132133308224 checkpoint_management.py:348] Couldn't match files for checkpoint /home/guillaume/cpp_work_space/cs-exercises/statistics/tensorflow/checkpoints/cifar_10/.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2000/2000 [==============================] - 33s 16ms/step - loss: 1.1148 - acc: 0.6021 - val_loss: 0.7597 - val_acc: 0.7344\n",
      "Epoch 2/1000\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 0.6654 - acc: 0.7662 - val_loss: 0.6742 - val_acc: 0.7653\n",
      "Epoch 3/1000\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 0.4964 - acc: 0.8225 - val_loss: 0.6489 - val_acc: 0.7841\n",
      "Epoch 4/1000\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 0.3994 - acc: 0.8567 - val_loss: 0.6863 - val_acc: 0.7795\n",
      "Epoch 5/1000\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 0.3359 - acc: 0.8797 - val_loss: 0.6881 - val_acc: 0.7885\n",
      "Epoch 6/1000\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 0.2986 - acc: 0.8937 - val_loss: 0.6854 - val_acc: 0.7882\n",
      "Epoch 7/1000\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 0.2739 - acc: 0.9033 - val_loss: 0.6799 - val_acc: 0.7992\n",
      "Epoch 8/1000\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 0.2518 - acc: 0.9112 - val_loss: 0.7257 - val_acc: 0.7952\n",
      "Epoch 9/1000\n",
      "2000/2000 [==============================] - 26s 13ms/step - loss: 0.2368 - acc: 0.9166 - val_loss: 0.7308 - val_acc: 0.7955\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=1000, steps_per_epoch=2000, validation_steps=1000, callbacks=callbacks,\n",
    "           validation_data=test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(image_data_generator.flow(train_data, train_label, batch_size=batch_size),\n",
    "                    epochs=1000, steps_per_epoch=2000, validation_data=(test_data, test_label), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 189us/sample - loss: 0.7134 - acc: 0.7960\n",
      "loss: 0.7134353098392486 acc: 0.7960000038146973\n"
     ]
    }
   ],
   "source": [
    "model.metrics_names\n",
    "\n",
    "loss, acc = model.evaluate(test_images, test_labels)\n",
    "print('loss: {} acc: {}'.format(loss, acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
